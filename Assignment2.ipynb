{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonardo/Projects/NLP_ASSIGNMENT_2/Assignment2/venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-11-23 16:12:35.381945: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-23 16:12:35.433007: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-23 16:12:35.433629: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-23 16:12:36.444386: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from datasets import Dataset\n",
    "import tensorflow as tf\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Arguments\n",
    "arguments_training_url = (\n",
    "    \"https://zenodo.org/records/8248658/files/arguments-training.tsv?download=1\"\n",
    ")\n",
    "arguments_validation_url = (\n",
    "    \"https://zenodo.org/records/8248658/files/arguments-validation.tsv?download=1\"\n",
    ")\n",
    "arguments_test_url = (\n",
    "    \"https://zenodo.org/records/8248658/files/arguments-test.tsv?download=1\"\n",
    ")\n",
    "\n",
    "### Human values\n",
    "labels_training_url = (\n",
    "    \"https://zenodo.org/records/8248658/files/labels-training.tsv?download=1\"\n",
    ")\n",
    "labels_validation_url = (\n",
    "    \"https://zenodo.org/records/8248658/files/labels-validation.tsv?download=1\"\n",
    ")\n",
    "labels_test_url = \"https://zenodo.org/records/8248658/files/labels-test.tsv?download=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating Training dataframe\n",
    "arguments_tr_df = pd.read_csv(arguments_training_url, sep=\"\\t\")\n",
    "labels_tr_df = pd.read_csv(labels_training_url, sep=\"\\t\")\n",
    "\n",
    "### Merging arguments and labels\n",
    "train_df_nm = pd.merge(arguments_tr_df, labels_tr_df, on=\"Argument ID\")\n",
    "\n",
    "### Creating Validation dataframe\n",
    "arguments_va_df = pd.read_csv(arguments_validation_url, sep=\"\\t\")\n",
    "labels_va_df = pd.read_csv(labels_validation_url, sep=\"\\t\")\n",
    "\n",
    "### Merging arguments and labels\n",
    "validation_df_nm = pd.merge(arguments_va_df, labels_va_df, on=\"Argument ID\")\n",
    "\n",
    "### Creating Test dataframe\n",
    "arguments_te_df = pd.read_csv(arguments_test_url, sep=\"\\t\")\n",
    "labels_te_df = pd.read_csv(labels_test_url, sep=\"\\t\")\n",
    "\n",
    "### Merging arguments and labels\n",
    "test_df_nm = pd.merge(arguments_te_df, labels_te_df, on=\"Argument ID\")\n",
    "\n",
    "### Notation\n",
    "### nm=not merged with logical OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Self-direction: thought</th>\n",
       "      <th>Self-direction: action</th>\n",
       "      <th>Stimulation</th>\n",
       "      <th>Hedonism</th>\n",
       "      <th>Achievement</th>\n",
       "      <th>Power: dominance</th>\n",
       "      <th>Power: resources</th>\n",
       "      <th>Face</th>\n",
       "      <th>Security: personal</th>\n",
       "      <th>Security: societal</th>\n",
       "      <th>Tradition</th>\n",
       "      <th>Conformity: rules</th>\n",
       "      <th>Conformity: interpersonal</th>\n",
       "      <th>Humility</th>\n",
       "      <th>Benevolence: caring</th>\n",
       "      <th>Benevolence: dependability</th>\n",
       "      <th>Universalism: concern</th>\n",
       "      <th>Universalism: nature</th>\n",
       "      <th>Universalism: tolerance</th>\n",
       "      <th>Universalism: objectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5393.000000</td>\n",
       "      <td>5393.000000</td>\n",
       "      <td>5393.000000</td>\n",
       "      <td>5393.000000</td>\n",
       "      <td>5393.000000</td>\n",
       "      <td>5393.000000</td>\n",
       "      <td>5393.000000</td>\n",
       "      <td>5393.000000</td>\n",
       "      <td>5393.000000</td>\n",
       "      <td>5393.000000</td>\n",
       "      <td>5393.000000</td>\n",
       "      <td>5393.000000</td>\n",
       "      <td>5393.000000</td>\n",
       "      <td>5393.000000</td>\n",
       "      <td>5393.000000</td>\n",
       "      <td>5393.000000</td>\n",
       "      <td>5393.000000</td>\n",
       "      <td>5393.000000</td>\n",
       "      <td>5393.000000</td>\n",
       "      <td>5393.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.183200</td>\n",
       "      <td>0.258669</td>\n",
       "      <td>0.045800</td>\n",
       "      <td>0.031893</td>\n",
       "      <td>0.280363</td>\n",
       "      <td>0.113110</td>\n",
       "      <td>0.115891</td>\n",
       "      <td>0.070833</td>\n",
       "      <td>0.370851</td>\n",
       "      <td>0.320415</td>\n",
       "      <td>0.105322</td>\n",
       "      <td>0.218246</td>\n",
       "      <td>0.038383</td>\n",
       "      <td>0.073243</td>\n",
       "      <td>0.246987</td>\n",
       "      <td>0.149453</td>\n",
       "      <td>0.385871</td>\n",
       "      <td>0.079177</td>\n",
       "      <td>0.123123</td>\n",
       "      <td>0.195439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.386867</td>\n",
       "      <td>0.437944</td>\n",
       "      <td>0.209071</td>\n",
       "      <td>0.175732</td>\n",
       "      <td>0.449218</td>\n",
       "      <td>0.316756</td>\n",
       "      <td>0.320124</td>\n",
       "      <td>0.256569</td>\n",
       "      <td>0.483077</td>\n",
       "      <td>0.466679</td>\n",
       "      <td>0.306996</td>\n",
       "      <td>0.413094</td>\n",
       "      <td>0.192137</td>\n",
       "      <td>0.260559</td>\n",
       "      <td>0.431299</td>\n",
       "      <td>0.356567</td>\n",
       "      <td>0.486845</td>\n",
       "      <td>0.270039</td>\n",
       "      <td>0.328608</td>\n",
       "      <td>0.396575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Self-direction: thought  Self-direction: action  Stimulation  \\\n",
       "count              5393.000000             5393.000000  5393.000000   \n",
       "mean                  0.183200                0.258669     0.045800   \n",
       "std                   0.386867                0.437944     0.209071   \n",
       "min                   0.000000                0.000000     0.000000   \n",
       "25%                   0.000000                0.000000     0.000000   \n",
       "50%                   0.000000                0.000000     0.000000   \n",
       "75%                   0.000000                1.000000     0.000000   \n",
       "max                   1.000000                1.000000     1.000000   \n",
       "\n",
       "          Hedonism  Achievement  Power: dominance  Power: resources  \\\n",
       "count  5393.000000  5393.000000       5393.000000       5393.000000   \n",
       "mean      0.031893     0.280363          0.113110          0.115891   \n",
       "std       0.175732     0.449218          0.316756          0.320124   \n",
       "min       0.000000     0.000000          0.000000          0.000000   \n",
       "25%       0.000000     0.000000          0.000000          0.000000   \n",
       "50%       0.000000     0.000000          0.000000          0.000000   \n",
       "75%       0.000000     1.000000          0.000000          0.000000   \n",
       "max       1.000000     1.000000          1.000000          1.000000   \n",
       "\n",
       "              Face  Security: personal  Security: societal    Tradition  \\\n",
       "count  5393.000000         5393.000000         5393.000000  5393.000000   \n",
       "mean      0.070833            0.370851            0.320415     0.105322   \n",
       "std       0.256569            0.483077            0.466679     0.306996   \n",
       "min       0.000000            0.000000            0.000000     0.000000   \n",
       "25%       0.000000            0.000000            0.000000     0.000000   \n",
       "50%       0.000000            0.000000            0.000000     0.000000   \n",
       "75%       0.000000            1.000000            1.000000     0.000000   \n",
       "max       1.000000            1.000000            1.000000     1.000000   \n",
       "\n",
       "       Conformity: rules  Conformity: interpersonal     Humility  \\\n",
       "count        5393.000000                5393.000000  5393.000000   \n",
       "mean            0.218246                   0.038383     0.073243   \n",
       "std             0.413094                   0.192137     0.260559   \n",
       "min             0.000000                   0.000000     0.000000   \n",
       "25%             0.000000                   0.000000     0.000000   \n",
       "50%             0.000000                   0.000000     0.000000   \n",
       "75%             0.000000                   0.000000     0.000000   \n",
       "max             1.000000                   1.000000     1.000000   \n",
       "\n",
       "       Benevolence: caring  Benevolence: dependability  Universalism: concern  \\\n",
       "count          5393.000000                 5393.000000            5393.000000   \n",
       "mean              0.246987                    0.149453               0.385871   \n",
       "std               0.431299                    0.356567               0.486845   \n",
       "min               0.000000                    0.000000               0.000000   \n",
       "25%               0.000000                    0.000000               0.000000   \n",
       "50%               0.000000                    0.000000               0.000000   \n",
       "75%               0.000000                    0.000000               1.000000   \n",
       "max               1.000000                    1.000000               1.000000   \n",
       "\n",
       "       Universalism: nature  Universalism: tolerance  \\\n",
       "count           5393.000000              5393.000000   \n",
       "mean               0.079177                 0.123123   \n",
       "std                0.270039                 0.328608   \n",
       "min                0.000000                 0.000000   \n",
       "25%                0.000000                 0.000000   \n",
       "50%                0.000000                 0.000000   \n",
       "75%                0.000000                 0.000000   \n",
       "max                1.000000                 1.000000   \n",
       "\n",
       "       Universalism: objectivity  \n",
       "count                5393.000000  \n",
       "mean                    0.195439  \n",
       "std                     0.396575  \n",
       "min                     0.000000  \n",
       "25%                     0.000000  \n",
       "50%                     0.000000  \n",
       "75%                     0.000000  \n",
       "max                     1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_nm.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Argument ID</th>\n",
       "      <th>Conclusion</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Premise</th>\n",
       "      <th>Self-direction: thought</th>\n",
       "      <th>Self-direction: action</th>\n",
       "      <th>Stimulation</th>\n",
       "      <th>Hedonism</th>\n",
       "      <th>Achievement</th>\n",
       "      <th>Power: dominance</th>\n",
       "      <th>...</th>\n",
       "      <th>Tradition</th>\n",
       "      <th>Conformity: rules</th>\n",
       "      <th>Conformity: interpersonal</th>\n",
       "      <th>Humility</th>\n",
       "      <th>Benevolence: caring</th>\n",
       "      <th>Benevolence: dependability</th>\n",
       "      <th>Universalism: concern</th>\n",
       "      <th>Universalism: nature</th>\n",
       "      <th>Universalism: tolerance</th>\n",
       "      <th>Universalism: objectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A01002</td>\n",
       "      <td>We should ban human cloning</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>we should ban human cloning as it will only ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A01005</td>\n",
       "      <td>We should ban fast food</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>fast food should be banned because it is reall...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A01006</td>\n",
       "      <td>We should end the use of economic sanctions</td>\n",
       "      <td>against</td>\n",
       "      <td>sometimes economic sanctions are the only thin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A01007</td>\n",
       "      <td>We should abolish capital punishment</td>\n",
       "      <td>against</td>\n",
       "      <td>capital punishment is sometimes the only optio...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A01008</td>\n",
       "      <td>We should ban factory farming</td>\n",
       "      <td>against</td>\n",
       "      <td>factory farming allows for the production of c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Argument ID                                   Conclusion       Stance  \\\n",
       "0      A01002                  We should ban human cloning  in favor of   \n",
       "1      A01005                      We should ban fast food  in favor of   \n",
       "2      A01006  We should end the use of economic sanctions      against   \n",
       "3      A01007         We should abolish capital punishment      against   \n",
       "4      A01008                We should ban factory farming      against   \n",
       "\n",
       "                                             Premise  Self-direction: thought  \\\n",
       "0  we should ban human cloning as it will only ca...                        0   \n",
       "1  fast food should be banned because it is reall...                        0   \n",
       "2  sometimes economic sanctions are the only thin...                        0   \n",
       "3  capital punishment is sometimes the only optio...                        0   \n",
       "4  factory farming allows for the production of c...                        0   \n",
       "\n",
       "   Self-direction: action  Stimulation  Hedonism  Achievement  \\\n",
       "0                       0            0         0            0   \n",
       "1                       0            0         0            0   \n",
       "2                       0            0         0            0   \n",
       "3                       0            0         0            0   \n",
       "4                       0            0         0            0   \n",
       "\n",
       "   Power: dominance  ...  Tradition  Conformity: rules  \\\n",
       "0                 0  ...          0                  0   \n",
       "1                 0  ...          0                  0   \n",
       "2                 1  ...          0                  0   \n",
       "3                 0  ...          0                  1   \n",
       "4                 0  ...          0                  0   \n",
       "\n",
       "   Conformity: interpersonal  Humility  Benevolence: caring  \\\n",
       "0                          0         0                    0   \n",
       "1                          0         0                    0   \n",
       "2                          0         0                    0   \n",
       "3                          0         0                    0   \n",
       "4                          0         0                    1   \n",
       "\n",
       "   Benevolence: dependability  Universalism: concern  Universalism: nature  \\\n",
       "0                           0                      0                     0   \n",
       "1                           0                      0                     0   \n",
       "2                           0                      0                     0   \n",
       "3                           0                      1                     0   \n",
       "4                           0                      1                     0   \n",
       "\n",
       "   Universalism: tolerance  Universalism: objectivity  \n",
       "0                        0                          0  \n",
       "1                        0                          0  \n",
       "2                        0                          0  \n",
       "3                        0                          0  \n",
       "4                        0                          0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_nm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Considering category ranges (0,3),(3,7),(7,13),(13,19)\n",
    "### adding +4, considering the first 4 columns which are not categories\n",
    "column_ranges = [(4, 7), (7, 11), (11, 17), (17, 23)]\n",
    "level_3_cat = [\n",
    "    \"Openness_to_change\",\n",
    "    \"Self_enhancement\",\n",
    "    \"Conversation\",\n",
    "    \"Self_transcendence\",\n",
    "]\n",
    "columns_to_keep = [\"Argument ID\", \"Conclusion\", \"Stance\", \"Premise\"]\n",
    "\n",
    "### Creating final dataframes\n",
    "train_df = pd.DataFrame()\n",
    "validation_df = pd.DataFrame()\n",
    "test_df = pd.DataFrame()\n",
    "\n",
    "### Applying OR to the selected columns using .any(axis=1)\n",
    "for (start, end), cat in zip(column_ranges, level_3_cat):\n",
    "    train_df[cat] = train_df_nm.iloc[:, start:end].any(axis=1)\n",
    "    validation_df[cat] = validation_df_nm.iloc[:, start:end].any(axis=1)\n",
    "    test_df[cat] = test_df_nm.iloc[:, start:end].any(axis=1)\n",
    "\n",
    "### Reading the columns to keep\n",
    "train_df = pd.concat([train_df_nm[columns_to_keep], train_df], axis=1)\n",
    "validation_df = pd.concat([validation_df_nm[columns_to_keep], validation_df], axis=1)\n",
    "test_df = pd.concat([test_df_nm[columns_to_keep], test_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Argument ID</th>\n",
       "      <th>Conclusion</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Premise</th>\n",
       "      <th>Openness_to_change</th>\n",
       "      <th>Self_enhancement</th>\n",
       "      <th>Conversation</th>\n",
       "      <th>Self_transcendence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A01002</td>\n",
       "      <td>We should ban human cloning</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>we should ban human cloning as it will only ca...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A01005</td>\n",
       "      <td>We should ban fast food</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>fast food should be banned because it is reall...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A01006</td>\n",
       "      <td>We should end the use of economic sanctions</td>\n",
       "      <td>against</td>\n",
       "      <td>sometimes economic sanctions are the only thin...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A01007</td>\n",
       "      <td>We should abolish capital punishment</td>\n",
       "      <td>against</td>\n",
       "      <td>capital punishment is sometimes the only optio...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A01008</td>\n",
       "      <td>We should ban factory farming</td>\n",
       "      <td>against</td>\n",
       "      <td>factory farming allows for the production of c...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Argument ID                                   Conclusion       Stance  \\\n",
       "0      A01002                  We should ban human cloning  in favor of   \n",
       "1      A01005                      We should ban fast food  in favor of   \n",
       "2      A01006  We should end the use of economic sanctions      against   \n",
       "3      A01007         We should abolish capital punishment      against   \n",
       "4      A01008                We should ban factory farming      against   \n",
       "\n",
       "                                             Premise  Openness_to_change  \\\n",
       "0  we should ban human cloning as it will only ca...               False   \n",
       "1  fast food should be banned because it is reall...               False   \n",
       "2  sometimes economic sanctions are the only thin...               False   \n",
       "3  capital punishment is sometimes the only optio...               False   \n",
       "4  factory farming allows for the production of c...               False   \n",
       "\n",
       "   Self_enhancement  Conversation  Self_transcendence  \n",
       "0             False          True               False  \n",
       "1             False          True               False  \n",
       "2              True          True               False  \n",
       "3             False          True                True  \n",
       "4             False          True                True  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Argument ID</th>\n",
       "      <th>Conclusion</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Premise</th>\n",
       "      <th>Openness_to_change</th>\n",
       "      <th>Self_enhancement</th>\n",
       "      <th>Conversation</th>\n",
       "      <th>Self_transcendence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1576</td>\n",
       "      <td>1576</td>\n",
       "      <td>1576</td>\n",
       "      <td>1576</td>\n",
       "      <td>1576</td>\n",
       "      <td>1576</td>\n",
       "      <td>1576</td>\n",
       "      <td>1576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1576</td>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>1548</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>A26004</td>\n",
       "      <td>We should ban naturopathy</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>We should develop adequate border protection. ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>183</td>\n",
       "      <td>868</td>\n",
       "      <td>2</td>\n",
       "      <td>1110</td>\n",
       "      <td>994</td>\n",
       "      <td>1082</td>\n",
       "      <td>1091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Argument ID                 Conclusion       Stance  \\\n",
       "count         1576                       1576         1576   \n",
       "unique        1576                        106            2   \n",
       "top         A26004  We should ban naturopathy  in favor of   \n",
       "freq             1                        183          868   \n",
       "\n",
       "                                                  Premise Openness_to_change  \\\n",
       "count                                                1576               1576   \n",
       "unique                                               1548                  2   \n",
       "top     We should develop adequate border protection. ...              False   \n",
       "freq                                                    2               1110   \n",
       "\n",
       "       Self_enhancement Conversation Self_transcendence  \n",
       "count              1576         1576               1576  \n",
       "unique                2            2                  2  \n",
       "top               False         True               True  \n",
       "freq                994         1082               1091  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Argument ID</th>\n",
       "      <th>Conclusion</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Premise</th>\n",
       "      <th>Openness_to_change</th>\n",
       "      <th>Self_enhancement</th>\n",
       "      <th>Conversation</th>\n",
       "      <th>Self_transcendence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A01001</td>\n",
       "      <td>Entrapment should be legalized</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>if entrapment can serve to more easily capture...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A01012</td>\n",
       "      <td>The use of public defenders should be mandatory</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>the use of public defenders should be mandator...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A02001</td>\n",
       "      <td>Payday loans should be banned</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>payday loans create a more impoverished societ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A02002</td>\n",
       "      <td>Surrogacy should be banned</td>\n",
       "      <td>against</td>\n",
       "      <td>Surrogacy should not be banned as it is the wo...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A02009</td>\n",
       "      <td>Entrapment should be legalized</td>\n",
       "      <td>against</td>\n",
       "      <td>entrapment is gravely immoral and against huma...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Argument ID                                       Conclusion       Stance  \\\n",
       "0      A01001                   Entrapment should be legalized  in favor of   \n",
       "1      A01012  The use of public defenders should be mandatory  in favor of   \n",
       "2      A02001                    Payday loans should be banned  in favor of   \n",
       "3      A02002                       Surrogacy should be banned      against   \n",
       "4      A02009                   Entrapment should be legalized      against   \n",
       "\n",
       "                                             Premise  Openness_to_change  \\\n",
       "0  if entrapment can serve to more easily capture...               False   \n",
       "1  the use of public defenders should be mandator...               False   \n",
       "2  payday loans create a more impoverished societ...               False   \n",
       "3  Surrogacy should not be banned as it is the wo...                True   \n",
       "4  entrapment is gravely immoral and against huma...               False   \n",
       "\n",
       "   Self_enhancement  Conversation  Self_transcendence  \n",
       "0             False          True               False  \n",
       "1             False         False                True  \n",
       "2             False          True                True  \n",
       "3             False         False               False  \n",
       "4             False          True                True  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "        ...  \n",
       "1571    False\n",
       "1572    False\n",
       "1573     True\n",
       "1574     True\n",
       "1575    False\n",
       "Name: Openness_to_change, Length: 1576, dtype: bool"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"Openness_to_change\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define a mapping for \"Stance\" column\n",
    "stance_mapping = {\"in favor of\": True, \"against\": False}\n",
    "\n",
    "### Apply the mapping to convert strings to boolean values\n",
    "train_df[\"Stance\"] = train_df[\"Stance\"].map(stance_mapping)\n",
    "validation_df[\"Stance\"] = validation_df[\"Stance\"].map(stance_mapping)\n",
    "test_df[\"Stance\"] = test_df[\"Stance\"].map(stance_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Argument ID</th>\n",
       "      <th>Conclusion</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Premise</th>\n",
       "      <th>Openness_to_change</th>\n",
       "      <th>Self_enhancement</th>\n",
       "      <th>Conversation</th>\n",
       "      <th>Self_transcendence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A01002</td>\n",
       "      <td>We should ban human cloning</td>\n",
       "      <td>True</td>\n",
       "      <td>we should ban human cloning as it will only ca...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A01005</td>\n",
       "      <td>We should ban fast food</td>\n",
       "      <td>True</td>\n",
       "      <td>fast food should be banned because it is reall...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A01006</td>\n",
       "      <td>We should end the use of economic sanctions</td>\n",
       "      <td>False</td>\n",
       "      <td>sometimes economic sanctions are the only thin...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A01007</td>\n",
       "      <td>We should abolish capital punishment</td>\n",
       "      <td>False</td>\n",
       "      <td>capital punishment is sometimes the only optio...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A01008</td>\n",
       "      <td>We should ban factory farming</td>\n",
       "      <td>False</td>\n",
       "      <td>factory farming allows for the production of c...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Argument ID                                   Conclusion  Stance  \\\n",
       "0      A01002                  We should ban human cloning    True   \n",
       "1      A01005                      We should ban fast food    True   \n",
       "2      A01006  We should end the use of economic sanctions   False   \n",
       "3      A01007         We should abolish capital punishment   False   \n",
       "4      A01008                We should ban factory farming   False   \n",
       "\n",
       "                                             Premise  Openness_to_change  \\\n",
       "0  we should ban human cloning as it will only ca...               False   \n",
       "1  fast food should be banned because it is reall...               False   \n",
       "2  sometimes economic sanctions are the only thin...               False   \n",
       "3  capital punishment is sometimes the only optio...               False   \n",
       "4  factory farming allows for the production of c...               False   \n",
       "\n",
       "   Self_enhancement  Conversation  Self_transcendence  \n",
       "0             False          True               False  \n",
       "1             False          True               False  \n",
       "2              True          True               False  \n",
       "3             False          True                True  \n",
       "4             False          True                True  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_list = [DummyClassifier(strategy=\"uniform\") for _ in level_3_cat]\n",
    "[\n",
    "    clf.fit(X=train_df[columns_to_keep[1:]], y=train_df[cat])\n",
    "    for clf, cat in zip(clf_list, level_3_cat)\n",
    "]\n",
    "prediction_uniform = np.array(\n",
    "    [clf.predict(X=test_df[columns_to_keep[1:]]) for clf in clf_list]\n",
    ").T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 score for Unifrom Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Classifier F1 overall weighted : 0.5144\n",
      "Random Classifier F1 overall macro: 0.4820\n",
      "Random Classifier F1 per category: [0.3607342378292099, 0.4246376811594203, 0.5750663129973476, 0.5676109032602886]\n"
     ]
    }
   ],
   "source": [
    "### Evaluate F1 overall\n",
    "f1_overall = f1_score(\n",
    "    y_true=test_df[level_3_cat], y_pred=prediction_uniform, average=\"weighted\"\n",
    ")\n",
    "print(f\"Random Classifier F1 overall weighted : {f1_overall:.4f}\")\n",
    "\n",
    "### Evaluate F1 overall\n",
    "f1_overall = f1_score(\n",
    "    y_true=test_df[level_3_cat], y_pred=prediction_uniform, average=\"macro\"\n",
    ")\n",
    "print(f\"Random Classifier F1 overall macro: {f1_overall:.4f}\")\n",
    "\n",
    "\n",
    "### Evaluate F1 per category\n",
    "f1_per_cat = [\n",
    "    f1_score(y_true=test_df[cat], y_pred=prediction_uniform[:, i])\n",
    "    for i, cat in enumerate(level_3_cat)\n",
    "]\n",
    "print(f\"Random Classifier F1 per category: {f1_per_cat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Majority Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_list = [DummyClassifier(strategy=\"most_frequent\") for _ in level_3_cat]\n",
    "[\n",
    "    clf.fit(X=train_df[columns_to_keep[1:]], y=train_df[cat])\n",
    "    for clf, cat in zip(clf_list, level_3_cat)\n",
    "]\n",
    "prediction_majority = np.array(\n",
    "    [clf.predict(X=test_df[columns_to_keep[1:]]) for clf in clf_list]\n",
    ").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48424676958457"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(\n",
    "    np.array(\n",
    "        [0.4018691588785046, 0.3937823834196891, 0.5768194070080863, 0.564516129032]\n",
    "    )\n",
    ") / 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 score for Majority Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Classifier F1 weighted : 0.5506\n",
      "Majority Classifier F1 macro: 0.4081\n",
      "Random Classifier F1 per category: [0.0, 0.0, 0.8141459744168548, 0.8181477315335584]\n"
     ]
    }
   ],
   "source": [
    "### Evaluate over all F1\n",
    "f1_overall = f1_score(\n",
    "    y_true=test_df[level_3_cat], y_pred=prediction_majority, average=\"weighted\"\n",
    ")\n",
    "print(f\"Majority Classifier F1 weighted : {f1_overall:.4f}\")\n",
    "\n",
    "### Evaluate over all F1\n",
    "f1_overall = f1_score(\n",
    "    y_true=test_df[level_3_cat], y_pred=prediction_majority, average=\"macro\"\n",
    ")\n",
    "print(f\"Majority Classifier F1 macro: {f1_overall:.4f}\")\n",
    "\n",
    "\n",
    "### Evaluate F1 per category\n",
    "f1_per_cat = [\n",
    "    f1_score(y_true=test_df[cat], y_pred=prediction_majority[:, i])\n",
    "    for i, cat in enumerate(level_3_cat)\n",
    "]\n",
    "print(f\"Random Classifier F1 per category: {f1_per_cat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convert dataframes into datasets\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "validation_dataset = Dataset.from_pandas(validation_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 16:12:44.297161: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 16:12:44.298273: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors=\"tf\")\n",
    "output = model(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'> (1, 12, 768)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'> (1, 768)\n"
     ]
    }
   ],
   "source": [
    "print(type(output[0]), output[0].shape)\n",
    "print(type(output[0]), output[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion Only Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Encoding for Conclusion only model\n",
    "def tokenize_conclusion(example):\n",
    "    ### Tokenize text columns\n",
    "    text_tokens = tokenizer(\n",
    "        example[\"Conclusion\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=tokenizer.model_max_length,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    ### Combine text tokens with non-text features\n",
    "    encoded_example = {\n",
    "        \"input_ids\": text_tokens[\"input_ids\"],\n",
    "        \"token_type_ids\": text_tokens[\"token_type_ids\"],\n",
    "        \"attention_mask\": text_tokens[\"attention_mask\"],\n",
    "        \"Openness_to_change\": torch.tensor(\n",
    "            example[\"Openness_to_change\"], dtype=tf.bool\n",
    "        ),\n",
    "        \"Self_enhancement\": torch.tensor(example[\"Self_enhancement\"], dtype=tf.bool),\n",
    "        \"Conversation\": torch.tensor(example[\"Conversation\"], dtype=tf.bool),\n",
    "        \"Self_transcendence\": torch.tensor(\n",
    "            example[\"Self_transcendence\"], dtype=tf.bool\n",
    "        ),\n",
    "    }\n",
    "    # print(encoded_example)\n",
    "    return encoded_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5393/5393 [00:01<00:00, 3547.99 examples/s]\n",
      "Map: 100%|██████████| 1896/1896 [00:00<00:00, 3546.38 examples/s]\n",
      "Map: 100%|██████████| 1576/1576 [00:00<00:00, 3801.03 examples/s]\n"
     ]
    }
   ],
   "source": [
    "### Tokenize train, validation, test datasets\n",
    "ds_list = [\n",
    "    d.map(tokenize_conclusion, batched=True)\n",
    "    for d in (train_dataset, validation_dataset, test_dataset)\n",
    "]\n",
    "\n",
    "### Set format for train, validation, test tokenized datasets\n",
    "columns = [\n",
    "    \"input_ids\",\n",
    "    \"token_type_ids\",\n",
    "    \"attention_mask\",\n",
    "    \"Openness_to_change\",\n",
    "    \"Self_enhancement\",\n",
    "    \"Conversation\",\n",
    "    \"Self_transcendence\",\n",
    "]\n",
    "\n",
    "train_tokenized_ds, valid_tokenized_ds, test_tokenized_ds = [\n",
    "    d.set_format(type=\"torch\", columns=columns) for d in ds_list\n",
    "]\n",
    "\n",
    "\n",
    "# ### Tokenize training data\n",
    "# test_tokenized_dataset = test_dataset.map(tokenize_conclusion, batched=True)\n",
    "# test_tokenized_dataset.set_format(\n",
    "#     \"tensorflow\",\n",
    "#     columns=[\n",
    "#         \"input_ids\",\n",
    "#         \"token_type_ids\",\n",
    "#         \"attention_mask\",\n",
    "#         \"Openness_to_change\",\n",
    "#         \"Self_enhancement\",\n",
    "#         \"Conversation\",\n",
    "#         \"Self_transcendence\",\n",
    "#     ],\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion - Premise Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Encoding for Conclusion - Premise model\n",
    "def tokenize_conclusion_premise(example):\n",
    "    ### Tokenize text columns\n",
    "    text_tokens = tokenizer(\n",
    "        example[\"Conclusion\"],\n",
    "        example[\"Premise\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=tokenizer.model_max_length,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    ### Combine text tokens with non-text features\n",
    "    encoded_example = {\n",
    "        \"input_ids\": text_tokens[\"input_ids\"],\n",
    "        \"token_type_ids\": text_tokens[\"token_type_ids\"],\n",
    "        \"attention_mask\": text_tokens[\"attention_mask\"],\n",
    "        \"Openness_to_change\": torch.tensor(\n",
    "            example[\"Openness_to_change\"], dtype=tf.float32\n",
    "        ),\n",
    "        \"Self_enhancement\": torch.tensor(example[\"Self_enhancement\"], dtype=tf.float32),\n",
    "        \"Conversation\": torch.tensor(example[\"Conversation\"], dtype=tf.float32),\n",
    "        \"Self_transcendence\": torch.tensor(\n",
    "            example[\"Self_transcendence\"], dtype=tf.float32\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    return encoded_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion - Premise - Stance Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Encoding for Conclusion - Premise - Stance model\n",
    "def tokenize_conclusion_premise_stance(example):\n",
    "    ### Tokenize text columns\n",
    "    text_tokens = tokenizer(\n",
    "        example[\"Conclusion\"],\n",
    "        example[\"Premise\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=tokenizer.model_max_length,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    ### Combine text tokens with non-text features\n",
    "    encoded_example = {\n",
    "        \"input_ids\": text_tokens[\"input_ids\"],\n",
    "        \"token_type_ids\": text_tokens[\"token_type_ids\"],\n",
    "        \"attention_mask\": text_tokens[\"attention_mask\"],\n",
    "        \"Stance\": tf.convert_to_tensor(\n",
    "            example[\"Stance\"], dtype=tf.int32\n",
    "        ),  ### Assuming 'Stance' is represented as 0 or 1\n",
    "        \"Openness_to_change\": tf.convert_to_tensor(\n",
    "            example[\"Openness_to_change\"], dtype=tf.float32\n",
    "        ),\n",
    "        \"Self_enhancement\": tf.convert_to_tensor(\n",
    "            example[\"Self_enhancement\"], dtype=tf.float32\n",
    "        ),\n",
    "        \"Conversation\": tf.convert_to_tensor(example[\"Conversation\"], dtype=tf.float32),\n",
    "        \"Self_transcendence\": tf.convert_to_tensor(\n",
    "            example[\"Self_transcendence\"], dtype=tf.float32\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    return encoded_example"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
